{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74584975",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# GPU Configuration\n",
    "# -----------------------------\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Parameters\n",
    "# -----------------------------\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 6\n",
    "EPOCHS = 40\n",
    "\n",
    "# -----------------------------\n",
    "# Improved Data Augmentation\n",
    "# -----------------------------\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './input/plant_village/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    './input/plant_village/test',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Stochastic Gradient Descent with Mini-batches\n",
    "# -----------------------------\n",
    "def stochastic_gradient_descent(epoch):\n",
    "    # Adaptive learning rate with decay as described\n",
    "    initial_lr = 0.01\n",
    "    decay_rate = 0.9\n",
    "    # Decreasing learning rate over time to aid convergence\n",
    "    return initial_lr * (decay_rate ** (epoch//5))\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Model Architecture Based on DCNN Components\n",
    "# -----------------------------\n",
    "def create_improved_dcnn_model():\n",
    "    model = Sequential([\n",
    "        # First Convolutional Layer\n",
    "        # Depth parameter: 32 filters to detect different features\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same',\n",
    "              input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        BatchNormalization(),\n",
    "        # Max Pooling as described for faster convergence\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Second Convolutional Layer with increased depth\n",
    "        # Stride parameter implemented in convolution\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same', strides=(1,1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Third Convolutional Layer with further increased depth\n",
    "        # Zero-padding parameter implemented with 'same' padding\n",
    "        Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # ReLU Layer is implemented in each Conv2D with activation='relu'\n",
    "\n",
    "        # Fully Connected Layer as described\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        # Final output with softmax activation for classification\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Using Stochastic Gradient Descent as described in the paragraphs\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # Loss layer implemented through loss function\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_improved_dcnn_model()\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# Training Callbacks\n",
    "# -----------------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "    LearningRateScheduler(stochastic_gradient_descent)  # Using our custom SGD scheduler\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Model Training with mini-batch SGD\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    train_generator,  # Using mini-batches as defined in BATCH_SIZE\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Visualization & Evaluation\n",
    "# -----------------------------\n",
    "# Plot training history\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Accuracy Evolution')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Loss Evolution')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "train_loss, train_acc = model.evaluate(train_generator, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(val_generator, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"{'Final Training Accuracy:':<25} {train_acc*100:.2f}%\")\n",
    "print(f\"{'Final Validation Accuracy:':<25} {val_acc*100:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save final model\n",
    "model.save(f'plant_disease_model_{val_acc*100:.1f}acc.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
